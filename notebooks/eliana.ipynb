{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Eliana Kariuki\n",
    "Student Pace: DSF-FT12-Hybrid\n",
    "Instructor Name: Samuel Karu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>studio</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>foreign_gross</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>BV</td>\n",
       "      <td>415000000.0</td>\n",
       "      <td>652000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice in Wonderland (2010)</td>\n",
       "      <td>BV</td>\n",
       "      <td>334200000.0</td>\n",
       "      <td>691300000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows Part 1</td>\n",
       "      <td>WB</td>\n",
       "      <td>296000000.0</td>\n",
       "      <td>664300000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inception</td>\n",
       "      <td>WB</td>\n",
       "      <td>292600000.0</td>\n",
       "      <td>535700000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shrek Forever After</td>\n",
       "      <td>P/DW</td>\n",
       "      <td>238700000.0</td>\n",
       "      <td>513900000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Twilight Saga: Eclipse</td>\n",
       "      <td>Sum.</td>\n",
       "      <td>300500000.0</td>\n",
       "      <td>398000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>Par.</td>\n",
       "      <td>312400000.0</td>\n",
       "      <td>311500000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tangled</td>\n",
       "      <td>BV</td>\n",
       "      <td>200800000.0</td>\n",
       "      <td>391000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Despicable Me</td>\n",
       "      <td>Uni.</td>\n",
       "      <td>251500000.0</td>\n",
       "      <td>291600000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How to Train Your Dragon</td>\n",
       "      <td>P/DW</td>\n",
       "      <td>217600000.0</td>\n",
       "      <td>277300000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title studio  domestic_gross  \\\n",
       "0                                  Toy Story 3     BV     415000000.0   \n",
       "1                   Alice in Wonderland (2010)     BV     334200000.0   \n",
       "2  Harry Potter and the Deathly Hallows Part 1     WB     296000000.0   \n",
       "3                                    Inception     WB     292600000.0   \n",
       "4                          Shrek Forever After   P/DW     238700000.0   \n",
       "5                   The Twilight Saga: Eclipse   Sum.     300500000.0   \n",
       "6                                   Iron Man 2   Par.     312400000.0   \n",
       "7                                      Tangled     BV     200800000.0   \n",
       "8                                Despicable Me   Uni.     251500000.0   \n",
       "9                     How to Train Your Dragon   P/DW     217600000.0   \n",
       "\n",
       "  foreign_gross  year  \n",
       "0     652000000  2010  \n",
       "1     691300000  2010  \n",
       "2     664300000  2010  \n",
       "3     535700000  2010  \n",
       "4     513900000  2010  \n",
       "5     398000000  2010  \n",
       "6     311500000  2010  \n",
       "7     391000000  2010  \n",
       "8     291600000  2010  \n",
       "9     277300000  2010  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = pd.read_csv(r'C:\\Users\\HomePC\\Documents\\labs\\Statistics\\box-office-movie-insights\\zippedData\\bom.movie_gross.csv\\bom.movie_gross.csv')\n",
    "movie_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3387 entries, 0 to 3386\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           3387 non-null   object \n",
      " 1   studio          3382 non-null   object \n",
      " 2   domestic_gross  3359 non-null   float64\n",
      " 3   foreign_gross   2037 non-null   object \n",
      " 4   year            3387 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 132.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame  \n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'studio', 'domestic_gross', 'foreign_gross', 'year'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the column names of the DataFrame\n",
    "movie_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the shape of the DataFrame\n",
    "movie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "studio               5\n",
       "domestic_gross      28\n",
       "foreign_gross     1350\n",
       "year                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of missing values in each column\n",
    "movie_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.359000e+03</td>\n",
       "      <td>3387.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.874585e+07</td>\n",
       "      <td>2013.958075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.698250e+07</td>\n",
       "      <td>2.478141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>2012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.400000e+06</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.790000e+07</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.367000e+08</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       domestic_gross         year\n",
       "count    3.359000e+03  3387.000000\n",
       "mean     2.874585e+07  2013.958075\n",
       "std      6.698250e+07     2.478141\n",
       "min      1.000000e+02  2010.000000\n",
       "25%      1.200000e+05  2012.000000\n",
       "50%      1.400000e+06  2014.000000\n",
       "75%      2.790000e+07  2016.000000\n",
       "max      9.367000e+08  2018.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the statistical summary information of the DataFrame\n",
    "movie_df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains information about box office movie insights. It includes 3,387 rows and 5 columns, with each row representing a movie. The columns provide the following details:\n",
    "\n",
    "1. **Shape**\n",
    "    - The DataFrame has 3,387 rows\n",
    "    - Each row represents a movie, and the columns\n",
    "\n",
    "2. **Columns**:\n",
    "    - `title`: The title of the movie (string).\n",
    "    - `studio`: The studio that produced the movie (string, with some missing values).\n",
    "    - `domestic_gross`: The domestic box office gross revenue (float, with some missing values).\n",
    "    - `foreign_gross`: The foreign box office gross revenue (string, with many missing values).\n",
    "    - `year`: The year the movie was released (integer).\n",
    "\n",
    "3. **Data Types**:\n",
    "    - The `domestic_gross` column is a float, while `foreign_gross` is a string (likely due to inconsistent formatting or missing values).\n",
    "    - The `title`, `studio`, and `year` columns are of type object (string) and integer, respectively.\n",
    "\n",
    "4. **Missing Values**:\n",
    "    - The `studio` column has 5 missing values.\n",
    "    - The `domestic_gross` column has 28 missing values.\n",
    "    - `foreign_gross`: The foreign box office gross revenue\n",
    "    - The `domestic_gross` column has 28 missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will then connect to the BOM IMDB data base to extract tables \n",
    "\n",
    "- Load the BOM movie gross data from the  CSV file.\n",
    "- Connect to the IMDb database and load the tables:\n",
    "\n",
    "  - `movie_basics`: Basic movie information.\n",
    "  - `writers`: Writer information linked to movies.\n",
    "  - `movie_ratings`: Movie ratings and vote counts..\n",
    "  - `persons`: Names and details of people (directors, writers, etc.).\n",
    "  - `directors`: Director information linked to movies\n",
    "Preview the datasets to understand their structure before merging and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load BOM dataset\n",
    "box_df = pd.read_csv(r'C:\\Users\\HomePC\\Documents\\labs\\Statistics\\box-office-movie-insights\\zippedData\\bom.movie_gross.csv\\bom.movie_gross.csv')\n",
    "\n",
    "# Connect to IMDB SQLite database\n",
    "conn = sqlite3.connect(r'C:\\Users\\HomePC\\Documents\\labs\\Statistics\\box-office-movie-insights\\zippedData\\im.db\\im.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name\n",
      "0   movie_basics\n",
      "1      directors\n",
      "2      known_for\n",
      "3     movie_akas\n",
      "4  movie_ratings\n",
      "5        persons\n",
      "6     principals\n",
      "7        writers\n"
     ]
    }
   ],
   "source": [
    "# Query to get the list of all tables in the database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Print the table names\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load key tables\n",
    "movie_basics = pd.read_sql_query(\"SELECT * FROM movie_basics\", conn)\n",
    "movie_ratings = pd.read_sql_query(\"SELECT * FROM movie_ratings\", conn)\n",
    "directors = pd.read_sql_query(\"SELECT * FROM directors\", conn)\n",
    "writers = pd.read_sql_query(\"SELECT * FROM writers\", conn)\n",
    "persons = pd.read_sql_query(\"SELECT * FROM persons\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movie_id                    primary_title              original_title  \\\n",
      "0  tt0063540                        Sunghursh                   Sunghursh   \n",
      "1  tt0066787  One Day Before the Rainy Season             Ashad Ka Ek Din   \n",
      "2  tt0069049       The Other Side of the Wind  The Other Side of the Wind   \n",
      "3  tt0069204                  Sabse Bada Sukh             Sabse Bada Sukh   \n",
      "4  tt0100275         The Wandering Soap Opera       La Telenovela Errante   \n",
      "5  tt0111414                      A Thin Life                 A Thin Life   \n",
      "6  tt0112502                          Bigfoot                     Bigfoot   \n",
      "7  tt0137204                  Joe Finds Grace             Joe Finds Grace   \n",
      "8  tt0139613                       O Silêncio                  O Silêncio   \n",
      "9  tt0144449            Nema aviona za Zagreb       Nema aviona za Zagreb   \n",
      "\n",
      "   start_year  runtime_minutes                      genres  \n",
      "0        2013            175.0          Action,Crime,Drama  \n",
      "1        2019            114.0             Biography,Drama  \n",
      "2        2018            122.0                       Drama  \n",
      "3        2018              NaN                Comedy,Drama  \n",
      "4        2017             80.0        Comedy,Drama,Fantasy  \n",
      "5        2018             75.0                      Comedy  \n",
      "6        2017              NaN             Horror,Thriller  \n",
      "7        2017             83.0  Adventure,Animation,Comedy  \n",
      "8        2012              NaN         Documentary,History  \n",
      "9        2012             82.0                   Biography  \n",
      "     movie_id  averagerating  numvotes\n",
      "0  tt10356526            8.3        31\n",
      "1  tt10384606            8.9       559\n",
      "2   tt1042974            6.4        20\n",
      "3   tt1043726            4.2     50352\n",
      "4   tt1060240            6.5        21\n",
      "5   tt1069246            6.2       326\n",
      "6   tt1094666            7.0      1613\n",
      "7   tt1130982            6.4       571\n",
      "8   tt1156528            7.2       265\n",
      "9   tt1161457            4.2       148\n",
      "    movie_id  person_id\n",
      "0  tt0285252  nm0899854\n",
      "1  tt0462036  nm1940585\n",
      "2  tt0835418  nm0151540\n",
      "3  tt0835418  nm0151540\n",
      "4  tt0878654  nm0089502\n",
      "5  tt0878654  nm2291498\n",
      "6  tt0878654  nm2292011\n",
      "7  tt0879859  nm2416460\n",
      "8  tt0996958  nm2286991\n",
      "9  tt0996958  nm2286991\n",
      "    movie_id  person_id\n",
      "0  tt0285252  nm0899854\n",
      "1  tt0438973  nm0175726\n",
      "2  tt0438973  nm1802864\n",
      "3  tt0462036  nm1940585\n",
      "4  tt0835418  nm0310087\n",
      "5  tt0835418  nm0841532\n",
      "6  tt0878654  nm0284943\n",
      "7  tt0878654  nm0284943\n",
      "8  tt0878654  nm0284943\n",
      "9  tt0996958  nm2286991\n",
      "   person_id       primary_name  birth_year  death_year  \\\n",
      "0  nm0061671  Mary Ellen Bauder         NaN         NaN   \n",
      "1  nm0061865       Joseph Bauer         NaN         NaN   \n",
      "2  nm0062070         Bruce Baum         NaN         NaN   \n",
      "3  nm0062195       Axel Baumann         NaN         NaN   \n",
      "4  nm0062798        Pete Baxter         NaN         NaN   \n",
      "5  nm0062879     Ruel S. Bayani         NaN         NaN   \n",
      "6  nm0063198              Bayou         NaN         NaN   \n",
      "7  nm0063432      Stevie Be-Zet         NaN         NaN   \n",
      "8  nm0063618          Jeff Beal      1963.0         NaN   \n",
      "9  nm0063750    Lindsay Beamish         NaN         NaN   \n",
      "\n",
      "                                 primary_profession  \n",
      "0         miscellaneous,production_manager,producer  \n",
      "1        composer,music_department,sound_department  \n",
      "2                        miscellaneous,actor,writer  \n",
      "3  camera_department,cinematographer,art_department  \n",
      "4  production_designer,art_department,set_decorator  \n",
      "5         director,production_manager,miscellaneous  \n",
      "6                                             actor  \n",
      "7                               composer,soundtrack  \n",
      "8              composer,music_department,soundtrack  \n",
      "9                             actress,miscellaneous  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, '\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview the first few rows of each table\n",
    "print(movie_basics.head(10)), \"\\n\"\n",
    "print(movie_ratings.head(10)), \"\\n\"\n",
    "print(directors.head(10)), \"\\n\"\n",
    "print(writers.head(10)), \"\\n\"\n",
    "print(persons.head(10)), \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Dropping Duplicates\n",
    "\n",
    "To ensure data consistency and avoid redundancy, we will drop all duplicate rows from the datasets. This process will be applied to each DataFrame individually. The `drop_duplicates()` method in pandas will be used for this purpose. This method removes duplicate rows based on all columns by default, ensuring that only unique rows remain in the DataFrame.\n",
    "\n",
    "Steps:\n",
    "1. Identify and remove duplicate rows in each DataFrame (`box_df`, `movie_basics`, `movie_ratings`, `directors`, `writers`, `persons`).\n",
    "2. Verify the changes by checking the shape of the DataFrames before and after removing duplicates.\n",
    "\n",
    "This step is crucial for maintaining the integrity of the data and ensuring accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking duplicates in box_df: 0 duplicates found.\n",
      "After dropping duplicates, box_df has shape: (3387, 5)\n",
      "Checking duplicates in movie_basics: 0 duplicates found.\n",
      "After dropping duplicates, movie_basics has shape: (146144, 6)\n",
      "Checking duplicates in movie_ratings: 0 duplicates found.\n",
      "After dropping duplicates, movie_ratings has shape: (73856, 3)\n",
      "Checking duplicates in directors: 127639 duplicates found.\n",
      "After dropping duplicates, directors has shape: (163535, 2)\n",
      "Checking duplicates in writers: 77521 duplicates found.\n",
      "After dropping duplicates, writers has shape: (178352, 2)\n",
      "Checking duplicates in persons: 0 duplicates found.\n",
      "After dropping duplicates, persons has shape: (606648, 5)\n"
     ]
    }
   ],
   "source": [
    "# Check and drop duplicates in each DataFrame\n",
    "datasets = {\n",
    "    \"box_df\": box_df,\n",
    "    \"movie_basics\": movie_basics,\n",
    "    \"movie_ratings\": movie_ratings,\n",
    "    \"directors\": directors,\n",
    "    \"writers\": writers,\n",
    "    \"persons\": persons\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Checking duplicates in {name}: {df.duplicated().sum()} duplicates found.\")\n",
    "    datasets[name] = df.drop_duplicates()\n",
    "    print(f\"After dropping duplicates, {name} has shape: {datasets[name].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Missing values can significantly impact data analysis and modeling. To address this issue, we will detect and handle missing values in the datasets. The following steps will be taken:\n",
    "\n",
    "1. **Detect Missing Values**:\n",
    "    - Use the `isnull()` method to identify missing values in each column of the DataFrame.\n",
    "    - Use the `sum()` method to count the total number of missing values in each column.\n",
    "\n",
    "2. **Handle Missing Values**:\n",
    "    - **Filling Missing Values**:\n",
    "      - For numerical columns, missing values can be filled with the mean, median, or a specific value.\n",
    "      - For categorical columns, missing values can be filled with the mode or a placeholder value.\n",
    "    - **Dropping Missing Values**:\n",
    "      - Rows or columns with a significant number of missing values can be dropped if they are not critical for analysis.\n",
    "\n",
    "3. **Implementation**:\n",
    "    - Analyze the percentage of missing values in each column to decide whether to fill or drop them.\n",
    "    - Apply the appropriate method to handle missing values based on the context of the data.\n",
    "\n",
    "This process ensures that the dataset is clean and ready for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id               0\n",
      "primary_title          0\n",
      "original_title        21\n",
      "start_year             0\n",
      "runtime_minutes    31739\n",
      "genres              5408\n",
      "dtype: int64\n",
      "movie_id         0\n",
      "averagerating    0\n",
      "numvotes         0\n",
      "dtype: int64\n",
      "movie_id     0\n",
      "person_id    0\n",
      "dtype: int64\n",
      "movie_id     0\n",
      "person_id    0\n",
      "dtype: int64\n",
      "person_id                  0\n",
      "primary_name               0\n",
      "birth_year            523912\n",
      "death_year            599865\n",
      "primary_profession     51340\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, '\\n')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the number of missing values in each table\n",
    "print(movie_basics.isnull().sum()), \"\\n\"\n",
    "print(movie_ratings.isnull().sum()), \"\\n\"\n",
    "print(directors.isnull().sum()), \"\\n\"\n",
    "print(writers.isnull().sum()), \"\\n\"\n",
    "print(persons.isnull().sum()), \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to handle missing values and duplicates\n",
    "def filling_missing(df):\n",
    "    # Dropping duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Dropping columns with more than 50% missing values\n",
    "    df = df.dropna(thresh=0.3 * len(df), axis=1)\n",
    "\n",
    "\n",
    "    # Filling missing values in numeric columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            skewness = df[col].skew()\n",
    "            fill_value = df[col].mean() if abs(skewness) < 0.5 else df[col].median()\n",
    "            df[col].fillna(fill_value, inplace=True)\n",
    "    \n",
    "    # Filling missing values in categorical columns\n",
    "    for col in df.select_dtypes(exclude=['number']).columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            most_frequent = df[col].mode()[0] if not df[col].mode().empty else \"Unknown\"\n",
    "            df[col].fillna(most_frequent, inplace=True)\n",
    "\n",
    "    return df\n",
    "# Apply filling_missing function to all DataFrames\n",
    "\n",
    "box_df = filling_missing(box_df)\n",
    "movie_basics = filling_missing(movie_basics)\n",
    "movie_ratings = filling_missing(movie_ratings)\n",
    "directors = filling_missing(directors)\n",
    "writers = filling_missing(writers)\n",
    "persons = filling_missing(persons)\n",
    "\n",
    "# Convert gross columns to numeric\n",
    "box_df['domestic_gross'] = pd.to_numeric(box_df['domestic_gross'], errors='coerce')\n",
    "box_df['foreign_gross'] = pd.to_numeric(box_df['foreign_gross'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- box_df ---\n",
      "Missing Values:\n",
      "title                0\n",
      "studio               5\n",
      "domestic_gross      28\n",
      "foreign_gross     1350\n",
      "year                 0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "title              0.00\n",
      "studio             0.15\n",
      "domestic_gross     0.83\n",
      "foreign_gross     39.86\n",
      "year               0.00\n",
      "dtype: float64%\n",
      "\n",
      "Number of Duplicates: 0\n",
      "\n",
      "--- movie_basics ---\n",
      "Missing Values:\n",
      "movie_id               0\n",
      "primary_title          0\n",
      "original_title        21\n",
      "start_year             0\n",
      "runtime_minutes    31739\n",
      "genres              5408\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "movie_id            0.00\n",
      "primary_title       0.00\n",
      "original_title      0.01\n",
      "start_year          0.00\n",
      "runtime_minutes    21.72\n",
      "genres              3.70\n",
      "dtype: float64%\n",
      "\n",
      "Number of Duplicates: 0\n",
      "\n",
      "--- movie_ratings ---\n",
      "Missing Values:\n",
      "movie_id         0\n",
      "averagerating    0\n",
      "numvotes         0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "movie_id         0.0\n",
      "averagerating    0.0\n",
      "numvotes         0.0\n",
      "dtype: float64%\n",
      "\n",
      "Number of Duplicates: 0\n",
      "\n",
      "--- directors ---\n",
      "Missing Values:\n",
      "movie_id     0\n",
      "person_id    0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "movie_id     0.0\n",
      "person_id    0.0\n",
      "dtype: float64%\n",
      "\n",
      "Number of Duplicates: 0\n",
      "\n",
      "--- writers ---\n",
      "Missing Values:\n",
      "movie_id     0\n",
      "person_id    0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "movie_id     0.0\n",
      "person_id    0.0\n",
      "dtype: float64%\n",
      "\n",
      "Number of Duplicates: 0\n",
      "\n",
      "--- persons ---\n",
      "Missing Values:\n",
      "person_id                  0\n",
      "primary_name               0\n",
      "birth_year            523912\n",
      "death_year            599865\n",
      "primary_profession     51340\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "person_id              0.00\n",
      "primary_name           0.00\n",
      "birth_year            86.36\n",
      "death_year            98.88\n",
      "primary_profession     8.46\n",
      "dtype: float64%\n",
      "\n",
      "Number of Duplicates: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for missing values and duplicates after cleaning\n",
    "def check_duplicates_missing(df, name):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Missing Values:\\n{df.isnull().sum()}\\n\")\n",
    "    print(f\"Percentage of Missing Values:\\n{(df.isnull().mean() * 100).round(2)}%\\n\")\n",
    "    print(f\"Number of Duplicates: {df.duplicated().sum()}\\n\")\n",
    "\n",
    "# Apply the function to all datasets\n",
    "for name, df in datasets.items():\n",
    "    check_duplicates_missing(df, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers from the dataset in using IQR\n",
    "The function `remove_outliers()` has been applied to remove outliers from the relevant columns in each DataFrame using the IQR method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.select_dtypes(include=['number']).columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "movie_ratings = remove_outliers(movie_ratings, ['averagerating', 'numvotes'])\n",
    "box_df = remove_outliers(box_df, ['domestic_gross', 'foreign_gross'])\n",
    "movie_basics = remove_outliers(movie_basics, ['runtime_minutes'])\n",
    "movie_ratings = remove_outliers(movie_ratings, ['averagerating', 'numvotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Merging Datasets\n",
    "\n",
    "Merging datasets is a crucial step in data analysis, especially when working with multiple related tables. It allows us to combine information from different sources into a single DataFrame for comprehensive analysis. In this project, we will merge the datasets based on common keys to create a unified dataset.\n",
    "\n",
    "#### Steps for Merging:\n",
    "1. **Identify Common Keys**:\n",
    "    - Determine the columns that serve as primary and foreign keys between the datasets. For example:\n",
    "      - `movie_id` is a common key between `movie_basics`, `movie_ratings`, `directors`, and `writers`.\n",
    "      - `person_id` is a common key between `directors`, `writers`, and `persons`.\n",
    "\n",
    "2. **Choose Merge Type**:\n",
    "    - Decide on the type of merge based on the analysis requirements:\n",
    "      - `inner`: Includes only matching rows from both datasets.\n",
    "      - `outer`: Includes all rows from both datasets, filling missing values with `NaN`.\n",
    "      - `left`: Includes all rows from the left dataset and matching rows from the right dataset.\n",
    "      - `right`: Includes all rows from the right dataset and matching rows from the left dataset.\n",
    "\n",
    "3. **Perform the Merge**:\n",
    "    - Use the `merge()` function in pandas to combine the datasets.\n",
    "\n",
    "4. **Verify the Result**:\n",
    "    - Check the shape and content of the merged dataset to ensure correctness.\n",
    "    - Handle any missing values or duplicates that may arise after merging.\n",
    "\n",
    "By merging the datasets, we can create a comprehensive dataset that combines movie details, ratings, directors, writers, and other relevant information for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 248 entries, 0 to 682\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   title            248 non-null    object \n",
      " 1   studio           248 non-null    object \n",
      " 2   domestic_gross   248 non-null    float64\n",
      " 3   foreign_gross    248 non-null    float64\n",
      " 4   year             248 non-null    int64  \n",
      " 5   movie_id         248 non-null    object \n",
      " 6   primary_title    248 non-null    object \n",
      " 7   original_title   248 non-null    object \n",
      " 8   start_year       248 non-null    int64  \n",
      " 9   runtime_minutes  248 non-null    float64\n",
      " 10  genres           248 non-null    object \n",
      " 11  averagerating    248 non-null    float64\n",
      " 12  numvotes         248 non-null    int64  \n",
      " 13  person_id_x      248 non-null    object \n",
      " 14  person_id_y      248 non-null    object \n",
      "dtypes: float64(4), int64(3), object(8)\n",
      "memory usage: 31.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Merge datasets\n",
    "# Merge BOM DataFrame with Movie Basics DataFrame based on title and primary_title\n",
    "merged_df = pd.merge(box_df, movie_basics, left_on='title', right_on='primary_title', how='inner')\n",
    "\n",
    "# merging with movie_ratings\n",
    "final_df = pd.merge(merged_df, movie_ratings, on='movie_id', how='inner')\n",
    "\n",
    "# Merging with directors\n",
    "final_df = pd.merge(final_df, directors, on='movie_id', how='left')\n",
    "\n",
    "# Merging with writers\n",
    "final_df = pd.merge(final_df, writers, on='movie_id', how='left')\n",
    "\n",
    "# Drop duplicates\n",
    "final_df = final_df.drop_duplicates(subset=['movie_id'])\n",
    "\n",
    "# Fill missing values\n",
    "final_df.fillna('Unknown', inplace=True)\n",
    "\n",
    "# Final check\n",
    "final_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "source": [
    "### Hypothesis Tests to be Conducted\n",
    "\n",
    "To gain insights into the relationships and differences in the dataset, we can conduct the following hypothesis:\n",
    "\n",
    "1. **Difference in Domestic Gross Revenue Across Genres**:\n",
    "    - **Null Hypothesis (\\(H_0\\))**: The mean domestic gross revenue is the same across different genres.\n",
    "    - **Alternative Hypothesis (\\(H_a\\))**: The mean domestic gross revenue differs across genres.\n",
    "    - **Test**: One-Way ANOVA Test.\n",
    "\n",
    "3. **Hypothesis for Top Actors**\n",
    "We will test if the involvement of top actors in a movie significantly affects its domestic box office earnings.\n",
    "\n",
    "- *Null Hypothesis (H0)*: The involvement of top actors does not significantly impact the movie's box office earnings.\n",
    "- *Alternative Hypothesis (H1)*: The involvement of top actors significantly impacts the movie's box office earnings.\n",
    "\n",
    "4. **Hypothesis for Top Producers**\n",
    "Similarly, we will test if the involvement of top producers significantly impacts the domestic box office earnings of a movie.\n",
    "\n",
    "- *Null Hypothesis (H0)*: The involvement of top producers does not significantly impact the movie's box office earnings.\n",
    "- *Alternative Hypothesis (H1)*: The involvement of top producers significantly impacts the movie's box office earnings.\n",
    "\n",
    "These tests will help us understand the relationships and differences in the dataset, providing valuable insights for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### ANOVA Test\n",
    "\n",
    "The Analysis of Variance (ANOVA) test is a statistical method used to determine whether there are significant differences between the means of three or more independent groups. In this context, we aim to analyze whether the domestic gross revenue of movies significantly differs across various genres.\n",
    "\n",
    "#### Key Points:\n",
    "1. **Null Hypothesis (\\(H_0\\))**: The mean domestic gross revenue is the same across all genres.\n",
    "2. **Alternative Hypothesis (\\(H_a\\))**: At least one genre has a significantly different mean domestic gross revenue.\n",
    "3. **Significance Level (\\(\\alpha\\))**: Typically set at 0.05. If the p-value is less than \\(\\alpha\\), we reject the null hypothesis.\n",
    "\n",
    "This test will help us understand if genre plays a significant role in influencing domestic gross revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Test Results:\n",
      "F-statistic: 0.6905481376103515\n",
      "P-value: 0.9663808044482705\n",
      "Fail to reject the null hypothesis: No significant difference in domestic gross revenue across genres.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Split the data into groups based on genres\n",
    "genre_groups = final_df.groupby('genres')['domestic_gross'].apply(list)\n",
    "\n",
    "# Perform one-way ANOVA test\n",
    "anova_result = f_oneway(*genre_groups)\n",
    "print(\"ANOVA Test Results:\")\n",
    "print(f\"F-statistic: {anova_result.statistic}\")\n",
    "print(f\"P-value: {anova_result.pvalue}\")\n",
    "\n",
    "# Interpret the results\n",
    "if anova_result.pvalue < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in domestic gross revenue across genres.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference in domestic gross revenue across genres.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "The ANOVA test results are as follows:\n",
    "\n",
    "- **F-statistic**: 0.6954\n",
    "- **P-value**: 0.9538\n",
    "\n",
    "### Interpretation:\n",
    "1. **Null Hypothesis (\\(H_0\\))**: The mean domestic gross revenue is the same across different genres.\n",
    "2. **Alternative Hypothesis (\\(H_a\\))**: The mean domestic gross revenue differs across genres.\n",
    "\n",
    "The **p-value** (0.9538) is much greater than the typical significance level (e.g., 0.05). This means we **fail to reject the null hypothesis**. \n",
    "\n",
    "### Conclusion:\n",
    "There is no statistically significant difference in the mean domestic gross revenue across different genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis for Top Actors\n",
    "\n",
    "We will test if the involvement of top actors in a movie significantly affects its domestic box office earnings.\n",
    "\n",
    "- *Null Hypothesis (H0)*: The involvement of top actors does not significantly impact the movie's box office earnings.\n",
    "- *Alternative Hypothesis (H1)*: The involvement of top actors significantly impacts the movie's box office earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Test Results:\n",
      "T-statistic: nan\n",
      "P-value: nan\n",
      "Fail to reject the null hypothesis: The involvement of top actors does not significantly impact the movie's box office earnings.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Define top actors based on their presence in the dataset\n",
    "top_actors = ['nm0000138', 'nm0000158', 'nm0000199']  # Example actor IDs (replace with actual IDs)\n",
    "\n",
    "# Filter movies with and without top actors\n",
    "movies_with_top_actors = final_df[final_df['person_id_x'].isin(top_actors)]\n",
    "movies_without_top_actors = final_df[~final_df['person_id_x'].isin(top_actors)]\n",
    "\n",
    "# Extract domestic gross revenue for both groups\n",
    "revenue_with_top_actors = movies_with_top_actors['domestic_gross']\n",
    "revenue_without_top_actors = movies_without_top_actors['domestic_gross']\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = ttest_ind(revenue_with_top_actors, revenue_without_top_actors, equal_var=False)\n",
    "\n",
    "# Print results\n",
    "print(\"T-Test Results:\")\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: The involvement of top actors significantly impacts the movie's box office earnings.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The involvement of top actors does not significantly impact the movie's box office earnings.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Perfoming ANOVA Testing for Average Ratings Across Genres\n",
    "\n",
    "In this context, we aim to analyze whether the average ratings of movies significantly differ across various genres.\n",
    "\n",
    "1. **Define Hypotheses**:\n",
    "    - **Null Hypothesis (\\(H_0\\))**: The mean average ratings are the same across all genres.\n",
    "    - **Alternative Hypothesis (\\(H_a\\))**: At least one genre has a significantly different mean average rating.\n",
    "\n",
    "2. **Group Data by Genres**:\n",
    "    - Group the dataset is by the `genres` column, and the average ratings for each genre are collected into separate groups.\n",
    "\n",
    "3. **Perform One-Way ANOVA**:\n",
    "    - The `f_oneway()` function from the `scipy.stats` library is used to perform the ANOVA test. This function compares the means of the groups and calculates the F-statistic and p-value.\n",
    "\n",
    "#### Significance of the Test:\n",
    "- The ANOVA test helps determine if genres play a significant role in influencing the average ratings of movies.\n",
    "\n",
    "This analysis provides insights into how audience ratings vary across genres, which can be valuable for understanding audience preferences and trends in the movie industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Test Results:\n",
      "F-statistic: 2.2747465485182827\n",
      "P-value: 5.044492843875728e-06\n",
      "Reject the null hypothesis: There is a significant difference in average ratings across genres.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Group the data by genres and collect average ratings\n",
    "genre_ratings = final_df.groupby('genres')['averagerating'].apply(list)\n",
    "\n",
    "# Perform one-way ANOVA test\n",
    "anova_result = f_oneway(*genre_ratings)\n",
    "print(\"ANOVA Test Results:\")\n",
    "print(f\"F-statistic: {anova_result.statistic}\")\n",
    "print(f\"P-value: {anova_result.pvalue}\")\n",
    "\n",
    "# Interpret the results\n",
    "if anova_result.pvalue < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in average ratings across genres.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference in average ratings across genres.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "source": [
    "### Explanation of Results\n",
    "\n",
    " ANOVA Test Results\n",
    "\n",
    "    - **F-statistic**: 2.2747 \n",
    "\n",
    "    - **P-value**: 5.0445e-06\n",
    "\n",
    "\n",
    "**Interpretation**:\n",
    " The p-value is significantly less than the typical significance level (0.05). This indicates that we reject the null hypothesis and conclude that there is a statistically significant difference in domestic gross revenue across genres."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
